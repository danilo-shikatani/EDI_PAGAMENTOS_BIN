import streamlit as st
import pandas as pd
import json

# --- 1. CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="Tradutor de EDI JSON", layout="wide")
st.title("ü§ñ Tradutor de Extratos EDI (JSON para Tabela)")
st.markdown("Fa√ßa o upload de um ou mais arquivos JSON (ex: BRED0070...) para convert√™-los em uma tabela CSV.")


# --- 2. √ÅREA DE UPLOAD ---
st.header("üì§ 1. Fa√ßa o Upload dos arquivos JSON")
uploaded_files = st.file_uploader(
    "Arraste e solte quantos arquivos JSON quiser",
    accept_multiple_files=True,
    type=['json']
)

# --- 3. BOT√ÉO PARA PROCESSAR E L√ìGICA DE TRANSFORMA√á√ÉO ---
if uploaded_files:
    if st.button("üöÄ Processar e Converter Arquivos"):
        all_dfs = [] # Lista para guardar todas as tabelas processadas
        total_records = 0

        with st.spinner("Processando... Lendo e achatando os arquivos JSON..."):
            for file in uploaded_files:
                try:
                    # L√™ o conte√∫do do arquivo JSON
                    data = json.load(file)

                    # --- ESTA √â A L√ìGICA PRINCIPAL (O "ACHATAMENTO") ---
                    # Identificamos que as "linhas" est√£o dentro da chave 'clientHeaders'
                    record_path_key = 'clientHeaders'

                    # Definimos quais dados do "cabe√ßalho" do arquivo queremos repetir em todas as linhas
                    meta_cols = [
                        ['fileHeader', 'processingDate'],
                        ['fileHeader', 'acquiringName'],
                        ['fileHeader', 'fileNumber']
                    ]

                    # Usamos json_normalize para converter o JSON aninhado em uma tabela plana
                    df_flat = pd.json_normalize(
                        data,
                        record_path=[record_path_key], # Diz onde est√£o as "linhas"
                        meta=meta_cols,                 # Puxa os metadados do cabe√ßalho
                        errors='ignore'                 # Ignora erros se alguma estrutura faltar
                    )
                    
                    all_dfs.append(df_flat)
                    total_records += len(df_flat)
                    
                except Exception as e:
                    st.error(f"Erro ao processar o arquivo '{file.name}': {e}. Certifique-se de que √© um JSON EDI v√°lido.")

            if all_dfs:
                # Junta todos os dataframes de todos os arquivos em um s√≥
                df_final = pd.concat(all_dfs, ignore_index=True)
                st.session_state['df_resultado'] = df_final # Salva na mem√≥ria do app
                
                st.balloons()
                st.success(f"Convers√£o conclu√≠da! {len(all_dfs)} arquivos processados, totalizando {total_records} registros encontrados.")

# --- 4. EXIBI√á√ÉO DO RESULTADO E DOWNLOAD ---
if 'df_resultado' in st.session_state:
    st.header("üìä 2. Tabela de Dados Consolidada")
    df_resultado_final = st.session_state['df_resultado']
    
    st.info(f"Visualizando {len(df_resultado_final)} linhas de dados. Use a barra de rolagem abaixo para ver todas as colunas.")
    st.dataframe(df_resultado_final)

    # Prepara os dados para download em CSV
    @st.cache_data
    def converter_df_para_csv(df):
        return df.to_csv(index=False, sep=';', encoding='utf-8-sig').encode('utf-8')

    csv_final = converter_df_para_csv(df_resultado_final)
    
    st.download_button(
        label="üì• Baixar Tabela Consolidada (CSV)",
        data=csv_final,
        file_name="dados_edi_consolidados.csv",
        mime="text/csv",
    )
